# Sparse-dRNN

![sparse-drnn](https://github.com/paulankita137/Sparse-dRNN/assets/53861279/58ddafbb-5d46-438f-8fb4-8a9d9b77de11)


The avenue of training differential recurrent neural networks
(d-RNNs) emerges as a promising route to address spatio-temporally
evolving systems. The effective learning of variable information gain
makes training d-RNNs important for their inherent derivative of states
property. In addition to training readout weights, the optimization of the
intrinsic recurrent connection of the d-RNNs prove significant for perfor-
mance enhancement. We introduce sparsity aware learning for feedback-
driven differential RNNs, tailored to adapt neuron-specific learnable thresh-
olds. This enables neurons with lower sparsity thresholds to play a more
significant role in decision-making processes, while simultaneously damp-
ening the influence of neurons with higher thresholds. This learning
paradigm is in addition to optimizing the recurrent connectivity matrix
of the d-RNN for mastering tasks demanding complex spatio-temporal
input-output mappings. Our learning approach yields networks capable
of accomplishing classification and sequential learning tasks with fewer
neurons while exhibiting heightened performance compared to existing
differential recurrent network training least-squares methods. 

This is a publicly available repository under development to implement sparsity aware learning  in feedback driven differential recurrent neural networks. 

Please contact ankita.paul@drexel.edu for questions regarding the theory, implementation or suggestions on code implementation and bugs that need to be addressed. 

![Figure 2024-07-07 181057](https://github.com/paulankita137/Sparse-dRNN/assets/53861279/ddb51900-cabc-4ea4-8198-246ec7ab3b23)

